====do everything with clas12-workflow =============================================
refer to 
https://github.com/baltzell/clas12-workflow
$CLAS12WFLOW/README.md

module load workflow/0.5
clas12-workflow.py -h

when we need to pause jobs
****************************
swif pause -workflow asdf
crontab -r
jkill 0
...Â­ wait until disaster is gone ...
swif run -workflow asdf or crontab swif.cron
****************************

check rcdb
python $CLAS12WFLOW/lib/clas12/RcdbManager.py 11014

import
swif import -file jobs/rgb_decode_R6223x1_x1200.json

run
swif run -workflow rgb_decode_R6223x1_x1200

check
swif-status.py 
swif-status.py | grep workflow_name
swif-status.py --workflow workflowName
swif-status.py --details --workflow workflowName

retry
swif-status.py --retry --workflow workflowName

cancel jobs
swif cancel -workflow workflowName

sweep clean
swif cancel -delete -workflow workflowName

cron 
cp $CLAS12WFLOW/cron/swif.cron ./
edit swif.cron
crontab swif.cron to install it and it will retry all jobs every 30m
crontab -e to edit
crontab -l to list
crontab -r to remove

== filter and merge ==================================================

remove old file first! otherwise it will be appended!!!!!

trigger skim
hipo-utils -filter -b "RUN::config,REC::Particle,REC::Calorimeter,REC::Cherenkov,RAW::vtp" -e "RAW::vtp" -merge -o out.hipo input.hipos

DC:
hipo-utils -filter -b "RUN::config,TimeBasedTrkg::TBHits,TimeBasedTrkg::TBSegments" -e "TimeBasedTrkg::TBHits" -merge -o output.hipo skim6*hipo


FTOF:
hipo-utils -filter -b "RUN::rf,RUN::config,REC::Event,REC::Particle,REC::Track,REC::Scintillator,FTOF::adc,FTOF::tdc,FTOF::hits,TimeBasedTrkg::TBTracks" -e "TimeBasedTrkg::TBTracks" -merge -o output.hipo skim6*hipo

HTCC:
hipo-utils -filter -b "RUN::rf,RUN::config,REC::Event,REC::Particle,REC::Track,REC::Scintillator,REC::Cherenkov,HTCC::.*" -e "HTCC::rec" -merge -o output.hipo skim6*hipo

CTOF:
hipo-utils -filter -b "RUN::rf,RUN::config,REC::Event,REC::Particle,REC::Track,REC::Scintillator,CTOF::hits,CTOF::adc,CTOF::tdc,CVTRec::Tracks" -e "CVTRec::Tracks" -merge -o output.hipo input*.hipo

CND:
hipo-utils -filter -b "RUN::config,CND::adc,CND::tdc,CND::hits,REC::Event,CVTRec::Tracks" -e "CND::hits" -merge -o output.hipo input*.hipo

FT:
hipo-utils -filter -b "RUN::config,REC::Event,REC::Particle,FT::particles,FTCAL::adc,FTCAL::hits,FTCAL::clusters,FTHODO::adc,FTHODO::hits,FTHODO::clusters" -e "FTCAL::clusters" -merge -o output.hipo input*.hipo

BAND:
hipo-utils -filter -b "RUN::config,REC::Event,REC::Particle,REC::Calorimeter,REC::Scintillator,REC::Track,REC::Traj,BAND::hits,BAND::tdc,BAND::adc" -e "BAND::hits" -merge -o output.hipo input*.hipo 

RF:
hipo-utils -filter -b "RF::tdc,RF::adc,RUN::rf,REC::Particle,REC::Scintillator,RUN::config" -e "RUN::config" -merge -o output.hipo input*.hipo

DST:
hipo-utils -filter -b "REC::Event,REC::Particle,REC::Calorimeter,REC::Scintillator,REC::Cherenkov,REC::Track,REC::Traj,REC::ForwardTagger,REC::CovMat,RICH::tdc,BAND::hits,CND::hits" -e "REC::Event" -merge -o output.hipo input*.hipo



== access clas online data =============================================================
(do this only when data mover is not working or too slow)
ssh hallgw
login with PIN+passcode from the mobile app
ssh clondaq6
cd /data/stage_in

==install clara and coatjava  ===========================
cd /work/clas12/rg-b

setenv clara_version 4.3.8
setenv coatjava_version 5.9.0

setenv clara_version 4.3.10
setenv coatjava_version 6c.2.1

setenv WORK /work/clas12/rg-b/clas12_clara${clara_version}_coatjava${coatjava_version}
setenv CLARA_HOME ${WORK}/clara

mkdir ${WORK}
cd ${WORK}

wget https://claraweb.jlab.org/clara/_downloads/install-claracre-clas.sh   
chmod 755 install-claracre-clas.sh
./install-claracre-clas.sh -f ${clara_version} -v ${coatjava_version} -g 2.1

setenv CLARA_USER_DATA ${WORK}

setenv CLARA_OUTPUT ${WORK}/output
setenv CLARA_LOG ${WORK}/log

mkdir $CLARA_OUTPUT
mkdir $CLARA_LOG

setenv CLARA_INPUT ${WORK}/input
ln -s /lustre/expphy/farm_out/${USER} ${WORK}/farm_out
ln -s /work/clas12/clas12/data/calib/decoded_single/ ${WORK}/input

setenv COATJAVA ${CLARA_HOME}/plugins/clas12

setenv PATH ${COATJAVA}/bin:$PATH

==run clara and coatjava, and other tools ===========================

cd /work/clas12/rg-b

setenv coatjava_version 5b.7.8
setenv clara_version 4.3.5
setenv WORK /work/clas12/rg-b/clas12_clara${clara_version}_coatjava${coatjava_version}
setenv CLARA_HOME ${WORK}/clara
setenv COATJAVA ${CLARA_HOME}/plugins/clas12
setenv PATH ${COATJAVA}/bin:$PATH
setenv CLARA_OUTPUT ${WORK}/output
setenv CLARA_LOG ${WORK}/log
setenv PATH ${GROOVY_HOME}/bin:$PATH
cd $WORK

setenv coatjava_version 5.9.0
setenv clara_version 4.3.8
setenv WORK /work/clas12/rg-b/clas12_clara${clara_version}_coatjava${coatjava_version}
setenv CLARA_HOME ${WORK}/clara
setenv COATJAVA ${CLARA_HOME}/plugins/clas12
setenv PATH ${COATJAVA}/bin:$PATH
setenv CLARA_USER_DATA ${WORK}
cd $WORK

mkdir /work/clas12/rg-b/clas12_clara4.3.10_coatjava6b.2.0
source /group/clas12/packages/setup.csh 
module load coatjava/6b.2.0
setenv CLARA_USER_DATA /work/clas12/rg-b/clas12_clara4.3.10_coatjava6b.2.0
cd $CLARA_USER_DATA

mkdir /work/clas12/rg-b/clas12_clara4.3.10_coatjava6.3.1
source /group/clas12/packages/setup.csh 
module load coatjava/6.3.1
setenv CLARA_USER_DATA /work/clas12/rg-b/clas12_clara4.3.10_coatjava6.3.1
cd $CLARA_USER_DATA

mkdir /work/clas12/rg-b/clas12_clara4.3.11_coatjava6b.4.0
source /group/clas12/packages/setup.csh 
module load coatjava/6b.4.0
setenv CLARA_USER_DATA /work/clas12/rg-b/clas12_clara4.3.11_coatjava6b.4.0
cd $CLARA_USER_DATA

$CLARA_HOME/bin/clara-shell /work/clas12/rg-b/clas12_cooking_rgb/script.clara_farm

$CLARA_HOME/bin/clara-shell /work/clas12/rg-b/clas12_cooking_rgb/script.clara_local

coatjava/bin/notsouseful-util

hipo-utils -stats ../production/recon/pass0/tmp/dst_clas_006489.evio.00000.hipo
hipo-utils -info ../production/recon/pass0/tmp/dst_clas_006489.evio.00000.hipo

hipo writer overwrite existing file by default

bash-4.2$ for xx in `/site/scicomp/auger-slurm/bin/slurmJobs -u clas12-1 | grep 'Feb-10 03:' | awk '{print$1'}`; do /site/scicomp/auger-slurm/bin/jkill $xx; done

#create new filelist from filelist difference
comm -23 allfile donefile | cat > leftfile

#rename "calib_" of file name in filelist
sed -i 's/calib_//g' filelist
sed -i 's/mon_//g' filelist
sed -i 's/dst_//g' filelist

#rename many file name
for xx in `ls */* | grep "hipo"` ; 
#do echo $xx
#do mv $xx $xx; 
do mv $xx `echo $xx | sed 's/0000/0004/g'`
done


#check database
https://clasweb.jlab.org/cgi-bin/ccdb/show_request?request=/calibration/htcc/gain:6213:default:2019-02-14_09-40-09

farm.scaling  multiples of 4 for farm18 and multiples of 2 for other to match their NUMA sockets

Does old pbs farm support exclusive beside slurm farm?
>>>>> No. However one can achieve the same with a few parameter settings like cpu and mem

for local job, will it use all memory by default?
Yes. By default it will use all available cores. However, you can set the core count (thus limit the memory use) by `set threads #`

for submitting a single job, don't set farm.scaling and just use default 0
otherwise, clara will create more jobs and could miss files

====decode with clas12-workflow (old) =============================================

#decode simulation
$CLARA_HOME/plugins/clas12/bin/evio2hipo -r 4310 -t -1 -s 1 -o $CLARA_INPUT/jpsi_gen_qf_1.hipo jpsi_gen_qf_1.evio
t for torus field scale, negative is electron inbending, s for solenoid field scale. 
They have to match what is defined in gcard by "SCALE_FIELD" option when evio file produced, otherwise reconstruction will be wrong !!!!!

#decode raw data
$CLARA_HOME/plugins/clas12/bin/decoder -t -1 -s -1 -o /work/clas12/rg-b/production/decoded/v1/006141/clas_006141.evio.00001.hipo /work/clas12/rg-b/data/clas_006141/clas_006141.evio.00001

/cache/clas12/rg-b/data/clas_pin_011077/clas_pin_011077.evio.00001

$CLARA_HOME/plugins/clas12/bin/decoder -t 1 -s -1 -o clas_006141.evio.00001.hipo /cache/clas12/rg-b/data/clas_pin_011077/clas_pin_011077.evio.00001

ls -l && rm -f in.evio && /bin/dd bs=1M if=/cache/clas12/rg-b/data/clas_006233/clas_006233.evio.00037 of=in.evio && unalias -a ; /work/clas12/rg-b/clas12_clara4.3.9_coatjava6b.1.1/clara/plugins/clas12/bin/decoder -c 2 -s -1.0000 -t -1.0000 -o out.hipo in.evio && ls out.hipo && /work/clas12/rg-b/clas12_clara4.3.9_coatjava6b.1.1/clara/plugins/clas12/bin/hipo-utils -test out.hipo || rm -f out.hipo && ls out.hipo

for filenum in {40..49}; do /work/clas12/rg-b/clas12_clara4.3.5_coatjava5b.7.8/clara/plugins/clas12/bin/decoder -t -1 -s -1 -o /cache/clas12/rg-b/production/decoded/v1/00$rnum/clas_00
$rnum.evio.000$filenum.hipo /cache/clas12/rg-b/data/clas_00$rnum/clas_00$rnum.evio.000$filenum & ; done;

#use clas12-workflow to do decoding
git clone --single-branch --branch hipo3 https://github.com/baltzell/clas12-workflow.git
cd clas12-workflow

mkdir output

source env.sh

./scripts/gen-decoding.py --runGroup rgb --workflow rgb_decode9 --task decode --run 6213 --inputs /cache/clas12/rg-b/data/clas_pin_006213 --fileRegex '.*_(\d+)\.evio\.(00[1-9]\d+)' --workDir /work/clas12/rg-b/clas12-workflow_hipo3/output  --outDir /work/clas12/rg-b/clas12-workflow_hipo3/output --coatjava /work/clas12/rg-b/clas12_clara4.3.5_coatjava5b.7.7/clara/plugins/clas12 --model 2

./scripts/gen-decoding.py --runGroup rgb --workflow rgb_decode --task decode --run 6210,6211 --inputs /cache/clas12/rg-b/data/ --workDir /work/clas12/rg-b/clas12-workflow_hipo3/output  --outDir /work/clas12/rg-b/clas12-workflow_hipo3/output --coatjava /work/clas12/rg-b/clas12_clara4.3.5_coatjava5b.7.7/clara/plugins/clas12  --model 2

by default it find all find under input 
--fileRegex ".*clas[_A-Za-z]*_(\d+)\.evio\.0004(\d+)"


== skim ===================================
clara1601.jlab.org and clara1602.jlab.org can be used for this

source /group/clas12/packages/setup.csh 
module load coatjava/6b.4.0

> common tasks always have this line there:
>
> MALLOC_ARENA_MAX=1; export MALLOC_ARENA_MAX
>
> You should use this, it limits how much memory JVM asks from the
>
> system. It helps a lot.

compile code
javac -cp "$COATJAVA/lib/clas/*:$COATJAVA/lib/utils/*:." filter_pid11.java

run code
java -DCLAS12DIR="$COATJAVA" -cp "$COATJAVA/lib/clas/*:$COATJAVA/lib/utils/*:." filter_pid11 file file_skim


another way
setenv  GROOVY_HOME /work/clas12/rg-b/groovy-2.5.6/
setenv PATH ${GROOVY_HOME}/bin:$PATH
run-groovy skim.groovy 

=== make new schema =========================================
mkdir hipo_20190424
cp /work/clas12/rg-b/clas12_clara4.3.8_coatjava5.9.0/clara/plugins/clas12/etc/bankdefs/hipo/* hipo_20190424/
python bankSplit_20190424.py hipo_20190424

mkdir hipo4_20190523
cp /group/clas12/packages/clara/4.4_6b.2.0/plugins/clas12/etc/bankdefs/hipo4/* hipo4_20190523/
python bankSplit_20190523.py hipo4_20190523

mkdir hipo4_20190722
cp /group/clas12/packages/clara/4.3.10_6b.3.0/plugins/clas12/etc/bankdefs/util/bankSplit.py bankSplit_20190722.py
edit bankSplit_20190722.py
cp /group/clas12/packages/clara/4.3.10_6b.3.0/plugins/clas12/etc/bankdefs/hipo4/* hipo4_20190722/
python bankSplit_20190722.py hipo4_20190722

mkdir hipo4_6.3.1_20190815
cp /group/clas12/packages/clara/4.3.10_6.3.1/plugins/clas12/etc/bankdefs/util/bankSplit.py bankSplit_6.3.1_20190815.py
edit bankSplit_6.3.1_20190815.py
cp /group/clas12/packages/clara/4.3.10_6.3.1/plugins/clas12/etc/bankdefs/hipo4/* hipo4_6.3.1_20190815/
python bankSplit_6.3.1_20190815.py hipo4_6.3.1_20190815

mkdir hipo4_6b.4.0_20191204
cp /group/clas12/packages/clara/4.3.11_6b.4.0/plugins/clas12/etc/bankdefs/util/bankSplit.py bankSplit_6b.4.0_20191204.py
edit bankSplit_6b.4.0_20191204.py
cp /group/clas12/packages/clara/4.3.11_6b.4.0/plugins/clas12/etc/bankdefs/hipo4/* hipo4_6b.4.0_20191204
python bankSplit_6b.4.0_20191204.py hipo4_6b.4.0_20191204

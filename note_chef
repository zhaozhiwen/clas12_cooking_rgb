
====do everything with clas12-workflow =============================================
refer to 
https://github.com/baltzell/clas12-workflow

module load workflow/0.5
module load workflow/dev

more $CLAS12WFLOW/README.md
clas12-workflow.py -h


when we need to pause jobs
****************************
swif pause -workflow asdf
crontab -r
jkill 0
...Â­ wait until disaster is gone ...
swif run -workflow asdf or crontab swif.cron
****************************
check rcdb
python $CLAS12WFLOW/lib/clas12/RcdbManager.py 11014

import
swif import -file rgb_decode_R6223x1_x1200.json

run
swif run -workflow rgb_decode_R6223x1_x1200

check
swif-status.py 
swif-status.py | grep workflow_name
swif-status.py --workflow workflowName
swif-status.py --details --workflow workflowName

retry
swif-status.py --retry --workflow workflowName

cancel jobs
swif cancel -workflow workflowName

sweep clean
swif cancel -delete -workflow workflowName

cron 
cp $CLAS12WFLOW/cron/swif.cron ./
edit swif.cron
crontab swif.cron to install it and it will retry all jobs every 30m
crontab -e to edit
crontab -l to list
crontab -r to remove

== filter and merge ==================================================

remove old file first! otherwise it will be appended!!!!!
hipo-utils won't give warning if any bank name is wrong, it simply ignore the bank!!!

trigger skim
hipo-utils -filter -b "RUN::config,REC::Particle,REC::Calorimeter,REC::Cherenkov,RAW::vtp" -e "RAW::vtp" -merge -o out.hipo input.hipos

DST:
hipo-utils -filter -b "REC::Event,REC::Particle,REC::Calorimeter,REC::Scintillator,REC::Cherenkov,REC::Track,REC::Traj,REC::ForwardTagger,REC::CovMat,RICH::tdc,BAND::hits,CND::hits" -e "REC::Event" -merge -o output.hipo input*.hipo

rename calib_rf skim1 skim1/*
rename calib_dc skim5 skim5/*
rename calib_ftof skim6 skim6/*
rename calib_htcc skim7 skim7/*
rename calib_ctof skim8 skim8/*
rename calib_cnd skim9 skim9/*
rename calib_ft skim10 skim10/*
rename calib_band skim11 skim11/*

== access clas online data =============================================================
(do this only when data mover is not working or too slow)
ssh hallgw
login with PIN+passcode from the mobile app
ssh clas@clondaq6
cd /data/stage_in

==install clara and coatjava  ===========================
cd /work/clas12/rg-b

setenv clara_version 4.3.8
setenv coatjava_version 5.9.0

setenv clara_version 4.3.10
setenv coatjava_version 6c.2.1

setenv WORK /work/clas12/rg-b/clas12_clara${clara_version}_coatjava${coatjava_version}
setenv CLARA_HOME ${WORK}/clara

mkdir ${WORK}
cd ${WORK}

wget https://claraweb.jlab.org/clara/_downloads/install-claracre-clas.sh   
chmod 755 install-claracre-clas.sh
./install-claracre-clas.sh -f ${clara_version} -v ${coatjava_version} -g 2.1

setenv CLARA_USER_DATA ${WORK}

setenv CLARA_OUTPUT ${WORK}/output
setenv CLARA_LOG ${WORK}/log

mkdir $CLARA_OUTPUT
mkdir $CLARA_LOG

setenv CLARA_INPUT ${WORK}/input
ln -s /lustre/expphy/farm_out/${USER} ${WORK}/farm_out
ln -s /work/clas12/clas12/data/calib/decoded_single/ ${WORK}/input

setenv COATJAVA ${CLARA_HOME}/plugins/clas12

setenv PATH ${COATJAVA}/bin:$PATH

==run clara and coatjava, and other tools ===========================

cd /work/clas12/rg-b

setenv coatjava_version 5b.7.8
setenv clara_version 4.3.5
setenv WORK /work/clas12/rg-b/clas12_clara${clara_version}_coatjava${coatjava_version}
setenv CLARA_HOME ${WORK}/clara
setenv COATJAVA ${CLARA_HOME}/plugins/clas12
setenv PATH ${COATJAVA}/bin:$PATH
setenv CLARA_OUTPUT ${WORK}/output
setenv CLARA_LOG ${WORK}/log
setenv PATH ${GROOVY_HOME}/bin:$PATH
cd $WORK

setenv coatjava_version 5.9.0
setenv clara_version 4.3.8
setenv WORK /work/clas12/rg-b/clas12_clara${clara_version}_coatjava${coatjava_version}
setenv CLARA_HOME ${WORK}/clara
setenv COATJAVA ${CLARA_HOME}/plugins/clas12
setenv PATH ${COATJAVA}/bin:$PATH
setenv CLARA_USER_DATA ${WORK}
cd $WORK

mkdir /work/clas12/rg-b/clas12_clara4.3.10_coatjava6b.2.0
source /group/clas12/packages/setup.csh 
module load coatjava/6b.2.0
setenv CLARA_USER_DATA /work/clas12/rg-b/clas12_clara4.3.10_coatjava6b.2.0
cd $CLARA_USER_DATA

mkdir /work/clas12/rg-b/clas12_clara4.3.10_coatjava6.3.1
source /group/clas12/packages/setup.csh 
module load coatjava/6.3.1
setenv CLARA_USER_DATA /work/clas12/rg-b/clas12_clara4.3.10_coatjava6.3.1
cd $CLARA_USER_DATA

mkdir /work/clas12/rg-b/clas12_clara4.3.11_coatjava6b.4.0
source /group/clas12/packages/setup.csh 
module load coatjava/6b.4.0
setenv CLARA_USER_DATA /work/clas12/rg-b/clas12_clara4.3.11_coatjava6b.4.0
cd $CLARA_USER_DATA

source /group/clas12/packages/setup.csh 
module load coatjava/6b.4.1

diff /group/clas12/packages/clara/4.3.12_6b.5.1/plugins/clas12/config/data.yaml /group/clas12/packages/clara/4.3.12_6b.5.0/plugins/clas12/config/data.yaml
diff /group/clas12/packages/clara/4.3.12_6b.5.0/plugins/clas12/etc/bankdefs/util/bankSplit.py /group/clas12/packages/clara/4.3.11_6b.4.0/plugins/clas12/etc/bankdefs/util/bankSplit.py

$CLARA_HOME/bin/clara-shell /work/clas12/rg-b/clas12_cooking_rgb/script.clara_farm

$CLARA_HOME/bin/clara-shell /work/clas12/rg-b/clas12_cooking_rgb/script.clara_local

coatjava/bin/notsouseful-util

hipo-utils -stats ../production/recon/pass0/tmp/dst_clas_006489.evio.00000.hipo
hipo-utils -info ../production/recon/pass0/tmp/dst_clas_006489.evio.00000.hipo

hipo writer overwrite existing file by default

bash-4.2$ for xx in `/site/scicomp/auger-slurm/bin/slurmJobs -u clas12-1 | grep 'Feb-10 03:' | awk '{print$1'}`; do /site/scicomp/auger-slurm/bin/jkill $xx; done

#create new filelist from filelist difference
comm -23 allfile donefile | cat > leftfile

#rename "calib_" of file name in filelist
sed -i 's/calib_//g' filelist
sed -i 's/mon_//g' filelist
sed -i 's/dst_//g' filelist

#rename many file name
for xx in `ls */* | grep "hipo"` ; 
#do echo $xx
#do mv $xx $xx; 
do mv $xx `echo $xx | sed 's/0000/0004/g'`
done


#check database
https://clasweb.jlab.org/cgi-bin/ccdb/show_request?request=/calibration/htcc/gain:6213:default:2019-02-14_09-40-09

farm.scaling  multiples of 4 for farm18 and multiples of 2 for other to match their NUMA sockets

Does old pbs farm support exclusive beside slurm farm?
>>>>> No. However one can achieve the same with a few parameter settings like cpu and mem

for local job, will it use all memory by default?
Yes. By default it will use all available cores. However, you can set the core count (thus limit the memory use) by `set threads #`

for submitting a single job, don't set farm.scaling and just use default 0
otherwise, clara will create more jobs and could miss files

====decode with clas12-workflow (old) =============================================

#decode simulation
$CLARA_HOME/plugins/clas12/bin/evio2hipo -r 4310 -t -1 -s 1 -o $CLARA_INPUT/jpsi_gen_qf_1.hipo jpsi_gen_qf_1.evio
t for torus field scale, negative is electron inbending, s for solenoid field scale. 
They have to match what is defined in gcard by "SCALE_FIELD" option when evio file produced, otherwise reconstruction will be wrong !!!!!

#decode raw data
$CLARA_HOME/plugins/clas12/bin/decoder -t -1 -s -1 -o /work/clas12/rg-b/production/decoded/v1/006141/clas_006141.evio.00001.hipo /work/clas12/rg-b/data/clas_006141/clas_006141.evio.00001

/cache/clas12/rg-b/data/clas_pin_011077/clas_pin_011077.evio.00001

$CLARA_HOME/plugins/clas12/bin/decoder -t 1 -s -1 -o clas_006141.evio.00001.hipo /cache/clas12/rg-b/data/clas_pin_011077/clas_pin_011077.evio.00001

ls -l && rm -f in.evio && /bin/dd bs=1M if=/cache/clas12/rg-b/data/clas_006233/clas_006233.evio.00037 of=in.evio && unalias -a ; /work/clas12/rg-b/clas12_clara4.3.9_coatjava6b.1.1/clara/plugins/clas12/bin/decoder -c 2 -s -1.0000 -t -1.0000 -o out.hipo in.evio && ls out.hipo && /work/clas12/rg-b/clas12_clara4.3.9_coatjava6b.1.1/clara/plugins/clas12/bin/hipo-utils -test out.hipo || rm -f out.hipo && ls out.hipo

for filenum in {40..49}; do /work/clas12/rg-b/clas12_clara4.3.5_coatjava5b.7.8/clara/plugins/clas12/bin/decoder -t -1 -s -1 -o /cache/clas12/rg-b/production/decoded/v1/00$rnum/clas_00
$rnum.evio.000$filenum.hipo /cache/clas12/rg-b/data/clas_00$rnum/clas_00$rnum.evio.000$filenum & ; done;

#use clas12-workflow to do decoding
git clone --single-branch --branch hipo3 https://github.com/baltzell/clas12-workflow.git
cd clas12-workflow

mkdir output

source env.sh

./scripts/gen-decoding.py --runGroup rgb --workflow rgb_decode9 --task decode --run 6213 --inputs /cache/clas12/rg-b/data/clas_pin_006213 --fileRegex '.*_(\d+)\.evio\.(00[1-9]\d+)' --workDir /work/clas12/rg-b/clas12-workflow_hipo3/output  --outDir /work/clas12/rg-b/clas12-workflow_hipo3/output --coatjava /work/clas12/rg-b/clas12_clara4.3.5_coatjava5b.7.7/clara/plugins/clas12 --model 2

./scripts/gen-decoding.py --runGroup rgb --workflow rgb_decode --task decode --run 6210,6211 --inputs /cache/clas12/rg-b/data/ --workDir /work/clas12/rg-b/clas12-workflow_hipo3/output  --outDir /work/clas12/rg-b/clas12-workflow_hipo3/output --coatjava /work/clas12/rg-b/clas12_clara4.3.5_coatjava5b.7.7/clara/plugins/clas12  --model 2

by default it find all find under input 
--fileRegex ".*clas[_A-Za-z]*_(\d+)\.evio\.0004(\d+)"


== skim ===================================
clara1601.jlab.org and clara1602.jlab.org can be used for this

source /group/clas12/packages/setup.csh 
module load coatjava/6b.4.0

> common tasks always have this line there:
>
> MALLOC_ARENA_MAX=1; export MALLOC_ARENA_MAX
>
> You should use this, it limits how much memory JVM asks from the
>
> system. It helps a lot.

compile code
javac -cp "$COATJAVA/lib/clas/*:$COATJAVA/lib/utils/*:." filter_pid11.java

run code
java -DCLAS12DIR="$COATJAVA" -cp "$COATJAVA/lib/clas/*:$COATJAVA/lib/utils/*:." filter_pid11 file file_skim


another way
setenv  GROOVY_HOME /work/clas12/rg-b/groovy-2.5.6/
setenv PATH ${GROOVY_HOME}/bin:$PATH
run-groovy skim.groovy 

=== make new schema =========================================
mkdir hipo_20190424
cp /work/clas12/rg-b/clas12_clara4.3.8_coatjava5.9.0/clara/plugins/clas12/etc/bankdefs/hipo/* hipo_20190424/
python bankSplit_20190424.py hipo_20190424

mkdir hipo4_20190523
cp /group/clas12/packages/clara/4.4_6b.2.0/plugins/clas12/etc/bankdefs/hipo4/* hipo4_20190523/
python bankSplit_20190523.py hipo4_20190523

mkdir hipo4_20190722
cp /group/clas12/packages/clara/4.3.10_6b.3.0/plugins/clas12/etc/bankdefs/util/bankSplit.py bankSplit_20190722.py
edit bankSplit_20190722.py
cp /group/clas12/packages/clara/4.3.10_6b.3.0/plugins/clas12/etc/bankdefs/hipo4/* hipo4_20190722/
python bankSplit_20190722.py hipo4_20190722

mkdir hipo4_6.3.1_20190815
cp /group/clas12/packages/clara/4.3.10_6.3.1/plugins/clas12/etc/bankdefs/util/bankSplit.py bankSplit_6.3.1_20190815.py
edit bankSplit_6.3.1_20190815.py
cp /group/clas12/packages/clara/4.3.10_6.3.1/plugins/clas12/etc/bankdefs/hipo4/* hipo4_6.3.1_20190815/
python bankSplit_6.3.1_20190815.py hipo4_6.3.1_20190815

mkdir hipo4_6b.4.0_20191204
cp /group/clas12/packages/clara/4.3.11_6b.4.0/plugins/clas12/etc/bankdefs/util/bankSplit.py bankSplit_6b.4.0_20191204.py
edit bankSplit_6b.4.0_20191204.py
cp /group/clas12/packages/clara/4.3.11_6b.4.0/plugins/clas12/etc/bankdefs/hipo4/* hipo4_6b.4.0_20191204
python bankSplit_6b.4.0_20191204.py hipo4_6b.4.0_20191204

=== yaml trick =============================================

To simplify things, you can use rga_fall2018 everywhere. This variation has default as a parent and differs for default only for DC,FTOF,ECAL geometries, target position and beam offsets. If you specify rga_fall2018 for other services as FT for example, it would be equivalent to use default.
>
> Does a combination of variation and timestamp completely determine a cooking condition in CCDB?
> Only one of them can'st?
If you specify only the timestamp, the code will use default as variation, which is not good for real data reconstruction because of geometry. If you specify a variation, you still want to specify a timestamp to freeze the constants that will be read from that variation. However there is one more caveat because I think the timestamp is applied only to the calibration constants and not to the geometry constants. If you point me to a log file, I can verify that.

> If I starting cooking now using an old timestamp, will I use old content of Rga_fall2018?
With the exception of geometry constants. See above.
Best regards,
	Raffaella


yaml file is pick
